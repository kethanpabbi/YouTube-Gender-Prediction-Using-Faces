{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is just a simple client example. Hack it as much as you want. \n",
    "\"\"\"\n",
    "import argparse\n",
    "import requests\n",
    "import jsonpickle\n",
    "import logging\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s.%(msecs)03d %(levelname)s %(module)s - %(funcName)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import collections\n",
    "import torch\n",
    "import numpy as np\n",
    "import data_loader.data_loaders as module_data\n",
    "import model.loss as module_loss\n",
    "import model.metric as module_metric\n",
    "import model.model as module_arch\n",
    "from parse_config import ConfigParser\n",
    "from trainer import Trainer\n",
    "from utils import prepare_device, update_lr_scheduler\n",
    "\n",
    "\n",
    "# fix random seeds for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# config = ConfigParser.from_args(args, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_face = \"http://127.0.0.1:10002/\"\n",
    "url_age_gender = \"http://127.0.0.1:10003/\"\n",
    "\n",
    "MAXIMUM_ENTROPY = {\"gender\": 0.6931471805599453, \"age\": 4.615120516841261}\n",
    "\n",
    "\n",
    "for image_path in tqdm(glob(\"./test-images/*\") + glob(\"./test-images-dangerous/*\")):\n",
    "    if \"ANNOTATED\" in image_path:\n",
    "        continue\n",
    "    logging.debug(f\"{image_path} loading image ...\")\n",
    "    with open(image_path, \"rb\") as stream:\n",
    "        binary_image = stream.read()\n",
    "\n",
    "    data = {\"image\": binary_image}\n",
    "    logging.info(f\"image loaded!\")\n",
    "\n",
    "    logging.debug(f\"sending image to server...\")\n",
    "    data = jsonpickle.encode(data)\n",
    "    response = requests.post(url_face, json=data)\n",
    "    logging.info(f\"got {response} from server!...\")\n",
    "    response = jsonpickle.decode(response.text)\n",
    "\n",
    "    face_detection_recognition = response[\"face_detection_recognition\"]\n",
    "    logging.info(f\"{len(face_detection_recognition)} faces deteced!\")\n",
    "\n",
    "    bboxes = [fdr[\"bbox\"] for fdr in face_detection_recognition]\n",
    "    det_scores = [fdr[\"det_score\"] for fdr in face_detection_recognition]\n",
    "    landmarks = [fdr[\"landmark\"] for fdr in face_detection_recognition]\n",
    "\n",
    "    logging.debug(f\"sending embeddings to server ...\")\n",
    "    data = [fdr[\"normed_embedding\"] for fdr in face_detection_recognition]\n",
    "\n",
    "    # -1 accounts for the batch size.\n",
    "    data = np.array(data).reshape(-1, 512).astype(np.float32)\n",
    "\n",
    "    # I wanna get rid of this pickling part but dunno how.\n",
    "    data = pickle.dumps(data)\n",
    "\n",
    "    data = {\"embeddings\": data}\n",
    "    data = jsonpickle.encode(data)\n",
    "    response = requests.post(url_age_gender, json=data)\n",
    "    logging.info(f\"got {response} from server!...\")\n",
    "\n",
    "    response = jsonpickle.decode(response.text)\n",
    "    ages = response[\"ages\"]\n",
    "    genders = response[\"genders\"]\n",
    "\n",
    "    logging.debug(f\"annotating image ...\")\n",
    "    image = Image.open(image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.truetype(\"fonts/arial.ttf\", 25)\n",
    "\n",
    "    for gender, age, bbox in zip(genders, ages, bboxes):\n",
    "        draw.rectangle(bbox.tolist(), outline=(0, 0, 0))\n",
    "        draw.text(\n",
    "            (bbox[0], bbox[1]),\n",
    "            f\"AGE: {round(age['mean'])} (entropy: {round(age['entropy'], 3)} / {round(MAXIMUM_ENTROPY['age'], 3)})\",\n",
    "            fill=(255, 0, 0),\n",
    "            font=font,\n",
    "        )\n",
    "        draw.text(\n",
    "            (bbox[0], bbox[3]),\n",
    "            \"MALE \" + str(round(gender[\"m\"] * 100)) + str(\"%\") + \", \"\n",
    "            \"FEMALE \"\n",
    "            + str(round(gender[\"f\"] * 100))\n",
    "            + str(\"%\")\n",
    "            + f\" (entropy: {round(gender['entropy'], 3)} / {round(MAXIMUM_ENTROPY['gender'], 3)})\",\n",
    "            fill=(0, 255, 0),\n",
    "            font=font,\n",
    "        )\n",
    "        image.save(image_path + \".ANNOTATED.jpg\")\n",
    "    logging.debug(f\"image annotated and saved at {image_path + '.ANNOTATED.jpg'}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5b36006495443554c8f0b17d9dc9f4d7cde294ee6cd3212b90a3ec2903a7e92"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
