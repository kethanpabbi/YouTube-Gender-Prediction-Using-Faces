{"cells":[{"cell_type":"markdown","source":["#Prerequistes"],"metadata":{"id":"J_F8_Y9v8Jff"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1662034832403,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"},"user_tz":-60},"id":"EA7oAozs-4fX","outputId":"8da41656-11bc-46fd-8720-cf02714ed1e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.7.13\n"]}],"source":["!python --version"]},{"cell_type":"markdown","source":["##Libraries"],"metadata":{"id":"DxBYU8pa8Qio"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50333,"status":"ok","timestamp":1662034883155,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"},"user_tz":-60},"id":"_0GIGivPx6Cg","outputId":"04a12c3f-6739-4291-9065-49deb81b3aea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting imageio==2.4.1\n","  Downloading imageio-2.4.1.tar.gz (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (1.21.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (7.1.2)\n","Building wheels for collected packages: imageio\n","  Building wheel for imageio (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imageio: filename=imageio-2.4.1-py3-none-any.whl size=3303885 sha256=48e1bd97adac6a2b885be056d1b9fa8ace58eeee7435fd8029024c5f7f517107\n","  Stored in directory: /root/.cache/pip/wheels/46/20/07/7bb9c8c44e6ec2efa60fd0e6280094f53f65f41767ef69a5ee\n","Successfully built imageio\n","Installing collected packages: imageio\n","  Attempting uninstall: imageio\n","    Found existing installation: imageio 2.9.0\n","    Uninstalling imageio-2.9.0:\n","      Successfully uninstalled imageio-2.9.0\n","Successfully installed imageio-2.4.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting youtube_dl\n","  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 6.7 MB/s \n","\u001b[?25hInstalling collected packages: youtube-dl\n","Successfully installed youtube-dl-2021.12.17\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting DeepFace\n","  Downloading deepface-0.0.75-py3-none-any.whl (65 kB)\n","\u001b[K     |████████████████████████████████| 65 kB 2.4 MB/s \n","\u001b[?25hRequirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from DeepFace) (2.8.0)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from DeepFace) (1.1.4)\n","Collecting retina-face>=0.0.1\n","  Downloading retina_face-0.0.12-py3-none-any.whl (15 kB)\n","Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.7/dist-packages (from DeepFace) (4.64.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from DeepFace) (1.21.6)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from DeepFace) (4.4.0)\n","Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from DeepFace) (2.8.2+zzzcolab20220719082949)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.7/dist-packages (from DeepFace) (4.6.0.66)\n","Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from DeepFace) (7.1.2)\n","Collecting mtcnn>=0.1.0\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 13.1 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from DeepFace) (1.3.5)\n","Collecting fire>=0.4.0\n","  Downloading fire-0.4.0.tar.gz (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.4.0->DeepFace) (1.15.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.4.0->DeepFace) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->DeepFace) (2.11.3)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->DeepFace) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->DeepFace) (1.1.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->DeepFace) (7.1.2)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->DeepFace) (2.23.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->DeepFace) (4.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->DeepFace) (3.8.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.2->DeepFace) (2.0.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->DeepFace) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->DeepFace) (2022.2.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (1.47.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (1.2.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (3.17.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (4.1.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (3.1.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (2.0.7)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (0.5.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (0.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (57.4.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (1.1.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (0.26.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (1.14.1)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (14.0.6)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->DeepFace) (2.8.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->DeepFace) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=1.9.0->DeepFace) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->DeepFace) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->DeepFace) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->DeepFace) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->DeepFace) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->DeepFace) (3.2.0)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->DeepFace) (1.7.1)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=3b073a60842d736921e057ff5c058dfe685777ce8a20ccbcba90a3662dfba4fa\n","  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n","Successfully built fire\n","Installing collected packages: retina-face, mtcnn, fire, DeepFace\n","Successfully installed DeepFace-0.0.75 fire-0.4.0 mtcnn-0.1.1 retina-face-0.0.12\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: retina-face in /usr/local/lib/python3.7/dist-packages (0.0.12)\n","Requirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.7/dist-packages (from retina-face) (4.6.0.66)\n","Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from retina-face) (7.1.2)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from retina-face) (4.4.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from retina-face) (1.21.6)\n","Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from retina-face) (2.8.2+zzzcolab20220719082949)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->retina-face) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->retina-face) (3.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->retina-face) (4.64.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->retina-face) (1.15.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->retina-face) (4.6.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (0.2.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (2.0.7)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (4.1.1)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (0.5.3)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (1.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (57.4.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (1.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (1.47.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (3.17.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (3.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (3.3.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (2.8.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (0.26.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (2.8.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (1.14.1)\n","Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (2.8.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (14.0.6)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->retina-face) (1.1.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->retina-face) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=1.9.0->retina-face) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (4.12.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (3.8.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=1.9.0->retina-face) (3.2.0)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->retina-face) (1.7.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cvlib\n","  Downloading cvlib-0.2.7.tar.gz (13.1 MB)\n","\u001b[K     |████████████████████████████████| 13.1 MB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cvlib) (1.21.6)\n","Collecting progressbar\n","  Downloading progressbar-2.5.tar.gz (10 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cvlib) (2.23.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from cvlib) (7.1.2)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from cvlib) (2.4.1)\n","Requirement already satisfied: imutils in /usr/local/lib/python3.7/dist-packages (from cvlib) (0.5.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->cvlib) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->cvlib) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->cvlib) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->cvlib) (3.0.4)\n","Building wheels for collected packages: cvlib, progressbar\n","  Building wheel for cvlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cvlib: filename=cvlib-0.2.7-py3-none-any.whl size=10046385 sha256=3c24d82ca2a85f91f32d00e4f35c51573fc5b42cbadf295fe0dde1daa93c21b5\n","  Stored in directory: /root/.cache/pip/wheels/8e/d7/31/bc643bd3a8b11a7368b1ab1d8a6299b33b462ed0b0683ddc5a\n","  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=9526e86027fb644a7c347e92c4cc29d820e5e16be33f65f484842710baaa649f\n","  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n","Successfully built cvlib progressbar\n","Installing collected packages: progressbar, cvlib\n","Successfully installed cvlib-0.2.7 progressbar-2.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: youtube_dl in /usr/local/lib/python3.7/dist-packages (2021.12.17)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting facenet_pytorch\n","  Downloading facenet_pytorch-2.5.2-py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 9.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (2.23.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (7.1.2)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (0.13.1+cu113)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from facenet_pytorch) (1.21.6)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->facenet_pytorch) (2.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (4.1.1)\n","Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->facenet_pytorch) (1.12.1+cu113)\n","Installing collected packages: facenet-pytorch\n","Successfully installed facenet-pytorch-2.5.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.1)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.6.0.66)\n","Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.8.0)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytube\n","  Downloading pytube-12.1.0-py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 3.3 MB/s \n","\u001b[?25hInstalling collected packages: pytube\n","Successfully installed pytube-12.1.0\n"]}],"source":["!pip install imageio==2.4.1\n","!pip install youtube_dl\n","!pip install opencv-python\n","!pip install keras\n","!pip install DeepFace\n","!pip install retina-face\n","!pip install cvlib\n","!pip install youtube_dl\n","!pip install facenet_pytorch\n","!pip install mtcnn\n","!pip install pytube"]},{"cell_type":"markdown","source":["##Mount drive"],"metadata":{"id":"UixCkHsF8TIL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12696,"status":"ok","timestamp":1662034895801,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"},"user_tz":-60},"id":"00O-1UJX0yMu","outputId":"18842909-2f33-4043-ade0-cf14eb38ce46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["#Face Detection and Gender Prediction"],"metadata":{"id":"c1eVY4aK8WdU"}},{"cell_type":"code","source":[" # Import Libraries\n","import cv2\n","import re\n","import numpy as np\n","import os\n","from moviepy.editor import *\n","import youtube_dl\n","import pandas as pd\n","from retinaface import RetinaFace\n","import cvlib as cv\n","from google.colab.patches import cv2_imshow\n","from deepface import DeepFace as dp\n","import numpy as np\n","import time\n","from pytube import YouTube\n","import pandas as pd"],"metadata":{"id":"WLvt9lJy16LE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTnb70-ExeJO","outputId":"53410fd8-6500-474e-ab4f-f2f997809999","executionInfo":{"status":"ok","timestamp":1661980073425,"user_tz":-60,"elapsed":1684878,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Enter URL: https://www.youtube.com/watch?v=5hEeOtYYVdQ\n","/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/video/BBC Minute News in 60 seconds - BBC News.mp4\n","Duration:60.680, FPS:50, Total Frames:3034\n","retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n","To: /root/.deepface/weights/retinaface.h5\n","100%|██████████| 119M/119M [00:13<00:00, 8.81MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["gender_model_weights.h5 will be downloaded...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://github.com/serengil/deepface_models/releases/download/v1.0/gender_model_weights.h5\n","To: /root/.deepface/weights/gender_model_weights.h5\n","100%|██████████| 537M/537M [00:52<00:00, 10.3MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Count = 1599\n","Total Duration: 60.680\n","Male Screen Time: 29.480\n","Female Screen Time:13.680\n","Total Non-Human Time: 17.540\n","[MoviePy] >>>> Building video /content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/processed_video/ex.mp4\n","[MoviePy] Writing video /content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/processed_video/ex.mp4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 3035/3035 [01:29<00:00, 33.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[MoviePy] Done.\n","[MoviePy] >>>> Video ready: /content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/processed_video/ex.mp4 \n","\n","Execution time: 1685.2450551986694\n"]}],"source":["start_time = time.time()\n","\n","def gender_predict(video):\n","    '''Predict the gender in a video'''\n","\n","    male_fps = 0\n","    female_fps = 0\n","    total_fps = 0\n","    global duration\n","    global fps\n","    global frame_count\n","    global count\n","    count = 0\n","\n","    try:\n","      # create a new cam object\n","      cap = cv2.VideoCapture(video)\n","      fps = cap.get(cv2.CAP_PROP_FPS)\n","      frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","      duration = frame_count/fps\n","      print(f'Duration:{duration:.3f}, FPS:{int(fps)}, Total Frames:{frame_count}')\n","      \n","      while True:\n","          \n","          # total frames\n","          total_fps += 1\n","          \n","          # read frame from video \n","          status, frame = cap.read()\n","\n","          # predict the faces\n","          # start_time2 = time.time()\n","          obj = RetinaFace.detect_faces(frame)\n","\n","          male_flag, female_flag = 0, 0\n","          \n","          if type(obj) != dict:\n","              cv2.imwrite('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/video_frames/'+str(total_fps)+'.jpg',frame)\n","          else:\n","              count += 1\n","              # Loop over the faces detected\n","              for key in obj.keys():\n","                  identity = obj[key]\n","                  \n","                  face_area = identity[\"facial_area\"]\n","                  cv2.imwrite('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/video_frames/0.jpg', cv2.resize(frame[face_area[1]:face_area[3], face_area[0]:face_area[2]], (224,224)))\n","                  dpa = dp.analyze('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/video_frames/0.jpg', actions = [\"gender\"],enforce_detection=False, detector_backend = 'retinaface')\n","                  label = dpa['gender']\n","\n","                  if label == 'Man':\n","                      male_flag = 1\n","                  if label == 'Woman': \n","                      female_flag = 1\n","\n","                  box_color = (255, 0, 0) if label == \"Man\" else (147, 20, 255)\n","                  cv2.rectangle(frame, (face_area[2], face_area[3]), (face_area[0], face_area[1]), box_color, 1)\n","                  \n","                  # Label processed image\n","                  cv2.putText(frame, label, (face_area[0],face_area[1]),\n","                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, box_color, 2)\n","              \n","\n","              if male_flag == 1:\n","                male_fps += 1\n","              if female_flag == 1:\n","                female_fps += 1\n","              # Save the processed image\n","              cv2.imwrite('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/video_frames/'+str(total_fps)+'.jpg',frame)\n","    \n","    except: Exception\n","    non_human_fps = 0\n","    print(f'Count = {count}')\n","    if male_fps + female_fps <= total_fps:\n","        non_human_fps = total_fps - (male_fps + female_fps)\n","        print(f'Total Duration: {duration:.3f}\\nMale Screen Time: {male_fps/fps:.3f}\\nFemale Screen Time:{female_fps/fps:.3f}\\nTotal Non-Human Time: {non_human_fps/fps:.3f}')\n","    \n","    \n","    col1 = \"Video\"\n","    col6 = \"Duration\"\n","    col2 = \"Male Screen Time\"\n","    col3 = \"Female Screen Time\"\n","    col4 = \"Non-Humqn Screen Time\"\n","    col5 = \"Views\"\n","    data = pd.DataFrame({col1:title,col6:duration,col2:male_fps/fps,col3:female_fps/fps,col4:non_human_fps/fps,col5:views})\n","    data.to_excel('YouTube_Stats.xlsx', sheet_name='sheet1', index=False)\n","    \n","    return \"\"\n","\n","def alpha_num(text):\n","    return str(re.sub(r'[^A-Za-z0-9 ]+', '', text))\n","\n","def atoi(text):\n","    '''Return numerical values'''\n","    return int(text) if text.isdigit() else text\n","\n","def natural_keys(text):\n","    '''Return list of values'''\n","    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n","\n","def remove_frames():\n","    '''Delete frames'''\n","    # Delete frames\n","    dir = '/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/video_frames'\n","    for f in os.listdir(dir):\n","        os.remove(os.path.join(dir, f))\n","\n","def img_to_vid():\n","    '''Convert sequence of frames into MP4 video'''\n","\n","    img_array = []\n","\n","    # Make an array of frames to be combined\n","    for filename in os.listdir('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/video_frames/'):\n","        if filename != '0.jpg':\n","            img_array.append(os.path.join('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/video_frames/',filename))\n","    \n","    # Sort the frames in order\n","    img_array.sort(key=natural_keys)\n","\n","    # Combine to form MP4 with required fps\n","    clip = ImageSequenceClip(img_array, fps=fps) \n","    clip.write_videofile(\"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/processed_video/\"+title+\".mp4\", fps=int(fps))\n","\n","    remove_frames()\n","\n","if __name__ == '__main__':\n","    \n","    global title\n","    global views\n","    # https://www.youtube.com/watch?v=5hEeOtYYVdQ\n","    url = input(\"Enter URL: \")\n","    \n","    video = YouTube(url)\n","    title = video.title\n","    views = video.views\n","\n","    path = video.streams.filter(file_extension = \"mp4\").order_by('resolution')[-1].download('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/video')\n","    print(path)\n","    #path = '/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/Make It Extraordinary Albert Bartlett 10 Sec TV Ad 2021.mp4'\n","    gender_predict(path)\n","    img_to_vid()\n","\n","    end_time = time.time()\n","    print(f\"Execution time: {end_time-start_time}\")  #86 mins for a min long video"]},{"cell_type":"markdown","source":["#FACE DETECTION"],"metadata":{"id":"1yL8zronvmbr"}},{"cell_type":"markdown","source":["##DLIB"],"metadata":{"id":"_HpgcliUvrhJ"}},{"cell_type":"code","source":["!pip install face-recognition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"964PznQTwVZ-","executionInfo":{"status":"ok","timestamp":1661898827052,"user_tz":-60,"elapsed":36220,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}},"outputId":"9dd4fe49-ef95-4bd2-d9c9-73ab889c5c45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting face-recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting face-recognition-models>=0.3.0\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[K     |████████████████████████████████| 100.1 MB 20 kB/s \n","\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face-recognition) (19.24.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face-recognition) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face-recognition) (1.21.6)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face-recognition) (7.1.2)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566186 sha256=5ea9ea7a8ebe3a4f29601fee9333d601d1bdb605026636bca661cb9f46ccfe35\n","  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"]}]},{"cell_type":"code","source":["import dlib\n","import cv2\n","import time\n","\n","start_time = time.time()\n","#We create the model here with the weights placed as parameters\n","face_detect = dlib.cnn_face_detection_model_v1(\"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/weights/mmod_human_face_detector.dat\")\n","\n","cap = cv2.VideoCapture(\"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/Make It Extraordinary Albert Bartlett 10 Sec TV Ad 2021.mp4\")\n","count = 0\n","#try:\n","while True:\n","    ret, frame = cap.read()\n","    frame = cv2.resize(frame, (600, 400))\n","\n","    faces = face_detect(frame, )\n","        \n","    for face in faces:\n","        count += 1\n","        # In dlib in order to extract points we need to do this\n","        x1 = face.rect.left()\n","        y1 = face.rect.bottom()\n","        x2 = face.rect.right()\n","        y2 = face.rect.top()\n","        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 1)\n","    if cv2.waitKey(25) & 0xFF == ord('q'):\n","        break\n","#except: Exception\n","   \n","print(count)\n","cap.release()\n","cv2.destroyAllWindows()\n","end_time = time.time()\n","print(f\"Execution time: {end_time-start_time}\") "],"metadata":{"id":"gvk_i0sRufHA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import dlib\n","import cv2\n","import time\n","\n","detector = dlib.cnn_face_detection_model_v1(\"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/weights/mmod_human_face_detector.dat\")\n","start_time = time.time()\n","\n","path = '/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/img0.jpg'\n","img = cv2.imread(path)\n","\n","faces = detector(img, 1)\n","    \n","for face in faces:\n","    count += 1\n","    # In dlib in order to extract points we need to do this\n","    x1 = face.rect.left()\n","    y1 = face.rect.bottom()\n","    x2 = face.rect.right()\n","    y2 = face.rect.top()\n","    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 1)\n","\n","cv2.imwrite('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/img0(dlib).jpg',img)\n","\n","print(count)\n","#cap.release()\n","end_time = time.time()\n","print(f\"Execution time: {end_time-start_time}\") "],"metadata":{"id":"0hoIwMxa23Ct"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Facenet"],"metadata":{"id":"Ht19rkhO4AiN"}},{"cell_type":"code","source":["from facenet_pytorch import MTCNN\n","import torch\n","import cv2\n","import time\n","\n","start_time = time.time()\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"," \n","#Create the model\n","mtcnn = MTCNN(keep_all=True, device=device)\n"," \n","#Load the video and go from frame to frame\n","cap = cv2.VideoCapture(\"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/Make It Extraordinary Albert Bartlett 10 Sec TV Ad 2021.mp4\")\n","count = 0\n","while True:\n","   ret, frame = cap.read()\n","   if ret:\n","       frame = cv2.resize(frame, (600, 400))\n","\n","      #Here we are going to use the facenet detector\n","       boxes, conf = mtcnn.detect(frame)\n","\n","      # If there is no confidence that in the frame is a face, don't draw a rectangle around it\n","       if conf[0] !=  None:     \n","            for (x, y, w, h) in boxes:\n","                count += 1\n","                text = f\"{conf[0]*100:.2f}%\"\n","                x, y, w, h = int(x), int(y), int(w), int(h)\n","                cv2.rectangle(frame, (x, y), (w, h), (255, 255, 255), 1)\n","   else:\n","       break\n","\n","#Show the result\n","#If we were using Google Colab we would use their function cv2_imshow()\n","\n","#For displaying images/frames\n","   if cv2.waitKey(25) & 0xFF == ord('q'):\n","       break\n","\n","print(count)\n","cap.release()\n","cv2.destroyAllWindows()\n","end_time = time.time()\n","print(f\"Execution time: {end_time-start_time}\") "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiloWrmpwG8X","executionInfo":{"status":"ok","timestamp":1661730963758,"user_tz":-60,"elapsed":7692,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}},"outputId":"41a2752d-1e2c-4bb9-9f34-d873d5402fbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["164\n","Execution time: 7.263085126876831\n"]}]},{"cell_type":"code","source":["from facenet_pytorch import MTCNN\n","import torch\n","import cv2\n","import time\n","\n","start_time = time.time()\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"," \n","#Create the model\n","mtcnn = MTCNN(keep_all=True, device=device)\n","\n","path = '/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/img1.jpg'\n","img = cv2.imread(path)\n","boxes, conf = mtcnn.detect(img)\n","count = 0\n","# If there is no confidence that in the frame is a face, don't draw a rectangle around it\n","if conf[0] !=  None:     \n","    for (x, y, w, h) in boxes:\n","        count += 1\n","        text = f\"{conf[0]*100:.2f}%\"\n","        x, y, w, h = int(x), int(y), int(w), int(h)\n","        cv2.putText(\n","                      img, #numpy array on which text is written\n","                      \"FaceNet\", #text\n","                      (10,50), #position at which writing has to start\n","                      cv2.FONT_HERSHEY_SIMPLEX, #font family\n","                      2, #font size\n","                      (250, 100, 0, 0), #font color\n","                      3) #font stroke\n","        cv2.rectangle(img, (x, y), (w, h), (250, 100, 0, 0), 2)\n","cv2.imwrite('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/img1(facenet).jpg',img)\n","print(count)\n","# cap.release()\n","cv2.destroyAllWindows()\n","end_time = time.time()\n","print(f\"Execution time: {end_time-start_time}\") "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyx4SmQQ8K04","executionInfo":{"status":"ok","timestamp":1661903386086,"user_tz":-60,"elapsed":706,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}},"outputId":"d43ea20f-53d2-437e-cfd6-311e3145e1ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n","Execution time: 0.3332958221435547\n"]}]},{"cell_type":"markdown","source":["##OpenCV"],"metadata":{"id":"m_IRY1Y24rA3"}},{"cell_type":"code","source":["# Import Libraries\n","import cv2\n","import numpy as np\n","import numpy as np\n","import time\n","\n","start_time = time.time()\n","# Each Caffe Model impose the shape of the input image also image preprocessing is required like mean\n","# substraction to eliminate the effect of illunination changes\n","MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n","\n","# https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n","FACE_PROTO = \"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/weights/deploy.prototxt.txt\"\n","\n","# https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel\n","FACE_MODEL = \"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/weights/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n","\n","# load face Caffe model\n","face_net = cv2.dnn.readNetFromCaffe(FACE_PROTO, FACE_MODEL)\n","\n","\n","def get_faces(frame, confidence_threshold=0.8):\n","    '''Detect all the faces present in a frame'''\n","   \n","    # convert the frame into a blob to be ready for NN input\n","    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104, 177.0, 123.0))\n","  \n","    # set the image as input to the NN\n","    face_net.setInput(blob)\n","   \n","    # perform inference and get predictions\n","    output = np.squeeze(face_net.forward())\n","   \n","    # initialize the result list\n","    faces = []\n","    \n","    # Loop over the faces detected\n","    for i in range(output.shape[0]):\n","        confidence = output[i, 2]\n","        if confidence > confidence_threshold:\n","            box = output[i, 3:7] * \\\n","                np.array([frame.shape[1], frame.shape[0],\n","                         frame.shape[1], frame.shape[0]])\n","            \n","            # convert to integers\n","            start_x, start_y, end_x, end_y = box.astype(np.int)\n","            \n","            # widen the box a little\n","            start_x, start_y, end_x, end_y = start_x - \\\n","                10, start_y - 10, end_x + 10, end_y + 10\n","            start_x = 0 if start_x < 0 else start_x\n","            start_y = 0 if start_y < 0 else start_y\n","            end_x = 0 if end_x < 0 else end_x\n","            end_y = 0 if end_y < 0 else end_y\n","           \n","            # append to our list\n","            faces.append((start_x, start_y, end_x, end_y))\n","    return faces\n","\n","def get_optimal_font_scale(text, width):\n","    '''Determine the optimal font scale based on the hosting frame width'''\n","\n","    for scale in reversed(range(0, 60, 1)):\n","        textSize = cv2.getTextSize(text, fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=scale/10, thickness=1)\n","        new_width = textSize[0][0]\n","        if (new_width <= width):\n","            return scale/10\n","    return 1\n","\n","def gender_predict():\n","    '''Predict the gender in a video'''\n","\n","    male_fps = 0\n","    female_fps = 0\n","    total_fps = 0\n","    global duration\n","    global fps\n","    global count\n","    global frame_count\n","    count = 0\n","\n","    try:\n","        # create a new cam object\n","        cap = cv2.VideoCapture(\"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/Make It Extraordinary Albert Bartlett 10 Sec TV Ad 2021.mp4\")\n","        \n","        while True:\n","            status, frame = cap.read()\n","            frame = cv2.resize(frame, (600, 400))\n","            \n","            # predict the faces\n","            faces = get_faces(frame)\n","                \n","            \n","            # Loop over the faces detected\n","            for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n","                count += 1\n","                face_img = frame[start_y: end_y, start_x: end_x]\n","\n","                blob = cv2.dnn.blobFromImage(image=face_img, scalefactor=1.0, size=(\n","                    227, 227), mean=MODEL_MEAN_VALUES, swapRB=False, crop=False)\n","\n","                cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (255, 255, 255), 2)\n","                \n","            # Quit midway\n","            if cv2.waitKey(1) == ord(\"q\"):\n","                break\n","        \n","        # Cleanup\n","        cv2.destroyAllWindows()\n","    except: Exception\n","    print(count)\n","\n","if __name__ == '__main__':\n","    gender_predict()\n","    end_time = time.time()\n","    print(f\"Execution time: {end_time-start_time}\") \n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k3zami-i4SnA","executionInfo":{"status":"ok","timestamp":1661731210604,"user_tz":-60,"elapsed":14624,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}},"outputId":"c72f6897-389c-4d82-e651-5021da90ee69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["127\n","Execution time: 13.89093279838562\n"]}]},{"cell_type":"code","source":["# Import Libraries\n","import cv2\n","import numpy as np\n","import numpy as np\n","import time\n","\n","start_time = time.time()\n","# Each Caffe Model impose the shape of the input image also image preprocessing is required like mean\n","# substraction to eliminate the effect of illunination changes\n","MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n","\n","# https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt\n","FACE_PROTO = \"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/weights/deploy.prototxt.txt\"\n","\n","# https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20180205_fp16/res10_300x300_ssd_iter_140000_fp16.caffemodel\n","FACE_MODEL = \"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/weights/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n","\n","# load face Caffe model\n","face_net = cv2.dnn.readNetFromCaffe(FACE_PROTO, FACE_MODEL)\n","\n","\n","def get_faces(frame, confidence_threshold=0.5):\n","    '''Detect all the faces present in a frame'''\n","   \n","    # convert the frame into a blob to be ready for NN input\n","    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104, 177.0, 123.0))\n","  \n","    # set the image as input to the NN\n","    face_net.setInput(blob)\n","   \n","    # perform inference and get predictions\n","    output = np.squeeze(face_net.forward())\n","   \n","    # initialize the result list\n","    faces = []\n","    \n","    # Loop over the faces detected\n","    for i in range(output.shape[0]):\n","        confidence = output[i, 2]\n","        if confidence > confidence_threshold:\n","            box = output[i, 3:7] * \\\n","                np.array([frame.shape[1], frame.shape[0],\n","                         frame.shape[1], frame.shape[0]])\n","            \n","            # convert to integers\n","            start_x, start_y, end_x, end_y = box.astype(np.int)\n","            \n","            # widen the box a little\n","            start_x, start_y, end_x, end_y = start_x - \\\n","                10, start_y - 10, end_x + 10, end_y + 10\n","            start_x = 0 if start_x < 0 else start_x\n","            start_y = 0 if start_y < 0 else start_y\n","            end_x = 0 if end_x < 0 else end_x\n","            end_y = 0 if end_y < 0 else end_y\n","           \n","            # append to our list\n","            faces.append((start_x, start_y, end_x, end_y))\n","    return faces\n","\n","def get_optimal_font_scale(text, width):\n","    '''Determine the optimal font scale based on the hosting frame width'''\n","\n","    for scale in reversed(range(0, 60, 1)):\n","        textSize = cv2.getTextSize(text, fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=scale/10, thickness=1)\n","        new_width = textSize[0][0]\n","        if (new_width <= width):\n","            return scale/10\n","    return 1\n","\n","def gender_predict():\n","    '''Predict the gender in a video'''\n","\n","    male_fps = 0\n","    female_fps = 0\n","    total_fps = 0\n","    global duration\n","    global fps\n","    global count\n","    global frame_count\n","    count = 0\n","\n","    try:\n","        path = '/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/img0.jpg'\n","        frame = cv2.imread(path)\n","        faces = get_faces(frame)\n","        for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n","            count += 1\n","            face_img = frame[start_y: end_y, start_x: end_x]\n","\n","            blob = cv2.dnn.blobFromImage(image=face_img, scalefactor=1.0, size=(\n","                227, 227), mean=MODEL_MEAN_VALUES, swapRB=False, crop=False)\n","\n","            cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), (255, 255, 0, 255), 2)\n","            cv2.putText(\n","                      frame, #numpy array on which text is written\n","                      \"OpenCV\", #text\n","                      (10,50), #position at which writing has to start\n","                      cv2.FONT_HERSHEY_SIMPLEX, #font family\n","                      1, #font size\n","                      (255, 255, 0, 255), #font color\n","                      3) #font stroke\n","        cv2.imwrite('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/img0(opencv).jpg',frame)\n","        # Cleanup\n","        cv2.destroyAllWindows()\n","    except: Exception\n","    print(count)\n","\n","if __name__ == '__main__':\n","    gender_predict()\n","    end_time = time.time()\n","    print(f\"Execution time: {end_time-start_time}\") \n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebem_MONosz_","executionInfo":{"status":"ok","timestamp":1661896927841,"user_tz":-60,"elapsed":13,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}},"outputId":"0f92bca1-6f35-4396-c7f4-e9bd39154226"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","Execution time: 0.14382052421569824\n"]}]},{"cell_type":"markdown","source":["##RetinaFace"],"metadata":{"id":"Vo4AAns75kha"}},{"cell_type":"code","source":["from retinaface import RetinaFace as rf\n","import cv2\n","import time\n","\n","start_time = time.time()\n"," \n","cap = cv2.VideoCapture(\"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/Make It Extraordinary Albert Bartlett 10 Sec TV Ad 2021.mp4\")\n","count, face_count = 0, 0\n","try:\n","    while True:\n","        # read frame from video \n","        status, frame = cap.read()\n","        frame = cv2.resize(frame, (600, 400))\n","        # predict the faces\n","        obj = rf.detect_faces(frame, threshold = 0.75)\n","        if type(obj) != dict:\n","            continue\n","        else:\n","            count += 1\n","            # Loop over the faces detected\n","            for key in obj.keys():\n","                face_count += 1\n","                identity = obj[key]\n","                \n","                face_area = identity[\"facial_area\"]\n","                cv2.rectangle(frame, (face_area[2], face_area[3]), (face_area[0], face_area[1]), (255, 255, 0), 1)\n","            \n","        if cv2.waitKey(25) & 0xFF == ord('q'):\n","            break\n","except: Exception\n","print(face_count)\n","cap.release()\n","cv2.destroyAllWindows()\n","end_time = time.time()\n","print(f\"Execution time: {end_time-start_time}\") "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOkj6qbE5l8H","executionInfo":{"status":"ok","timestamp":1661731344441,"user_tz":-60,"elapsed":41092,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}},"outputId":"b2198553-fa69-4326-aa53-bd92e7c3d989"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["440\n","Execution time: 40.88335847854614\n"]}]},{"cell_type":"code","source":["from retinaface import RetinaFace as rf\n","import cv2\n","import time\n","\n","start_time = time.time()\n","path = '/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/img2.jpg'\n","img = cv2.imread(path)\n","obj = rf.detect_faces(img, threshold = 0.75)\n","face_count = 0\n","if type(obj) == dict:\n","    # Loop over the faces detected\n","    for key in obj.keys():\n","        face_count += 1\n","        identity = obj[key]\n","        \n","        face_area = identity[\"facial_area\"]\n","\n","        cv2.putText(\n","                      img, #numpy array on which text is written\n","                      \"RetinaFace\", #text\n","                      (10,50), #position at which writing has to start\n","                      cv2.FONT_HERSHEY_SIMPLEX, #font family\n","                      2, #font size\n","                      (0, 255, 255), #font color\n","                      3) #font stroke\n","\n","        cv2.rectangle(img, (face_area[2], face_area[3]), (face_area[0], face_area[1]), (0, 255, 255), 1)\n","cv2.imwrite('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/retinaface-img2.jpg',img)  \n","print(face_count)\n","end_time = time.time()\n","print(f\"Execution time: {end_time-start_time}\") "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrQDJHGhQ-PV","executionInfo":{"status":"ok","timestamp":1661905569268,"user_tz":-60,"elapsed":811,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}},"outputId":"b3768b6d-0f07-46d4-b6c4-72eedb7ac1bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["13\n","Execution time: 0.5800893306732178\n"]}]},{"cell_type":"markdown","source":["##MTCNN"],"metadata":{"id":"bMu2ACnv6Biu"}},{"cell_type":"code","source":["from mtcnn import MTCNN\n","import cv2\n","import time\n","\n","start_time = time.time()\n","#Load the haarcascade file\n","detector = MTCNN()\n"," \n","cap = cv2.VideoCapture(\"/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/Make It Extraordinary Albert Bartlett 10 Sec TV Ad 2021.mp4\")\n","count = 0\n","try:\n","    while(True):\n","        ret, frame = cap.read()\n","        frame = cv2.resize(frame, (600, 400))\n","        boxes = detector.detect_faces(frame)\n","        for box in boxes:\n","            count += 1\n","            x, y, w, h = box['box']\n","\n","            cv2.rectangle(frame, (x, y), (x+w, y+h), \n","                                (255, 0, 0), 2)\n","        \n","        if cv2.waitKey(25) & 0xFF == ord('q'):\n","            break\n","except: Exception\n","print(count)\n","cap.release()\n","cv2.destroyAllWindows()\n","end_time = time.time()\n","print(f\"Execution time: {end_time-start_time}\") "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qq70-dz35IgE","executionInfo":{"status":"ok","timestamp":1661731885006,"user_tz":-60,"elapsed":127132,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}},"outputId":"c3637294-2baa-4c22-c7c0-b3426252159b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["174\n","Execution time: 125.92230319976807\n"]}]},{"cell_type":"code","source":["from mtcnn import MTCNN\n","import cv2\n","import time\n","\n","start_time = time.time()\n","#Load the haarcascade file\n","detector = MTCNN()\n","\n","# except: Exception\n","path = '/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/img2.jpg'\n","img = cv2.imread(path)\n","count = 0\n","boxes = detector.detect_faces(img)\n","for box in boxes:\n","    count += 1\n","    x, y, w, h = box['box']\n","    cv2.putText(\n","                      img, #numpy array on which text is written\n","                      \"MTCNN\", #text\n","                      (10,50), #position at which writing has to start\n","                      cv2.FONT_HERSHEY_SIMPLEX, #font family\n","                      2, #font size\n","                      (255, 255, 0, 255), #font color\n","                      2) #font stroke\n","        \n","    cv2.rectangle(img, (x, y), (x+w, y+h), \n","                        (255, 255, 0, 255), 1)\n","print(count)\n","cv2.imwrite('/content/drive/MyDrive/YouTube-Gender-Prediction-Using-Faces-main/Data/Gender Detection/test_images/mtcnn-img2.jpg',img)\n","\n","#cap.release()\n","cv2.destroyAllWindows()\n","end_time = time.time()\n","print(f\"Execution time: {end_time-start_time}\") "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZowpBszNNfNk","executionInfo":{"status":"ok","timestamp":1661904872487,"user_tz":-60,"elapsed":1696,"user":{"displayName":"kethan Pabbi","userId":"13020954653687775065"}},"outputId":"b32ce8e9-ddda-40e3-9d6a-705bbdeca0eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n","Execution time: 1.5873701572418213\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bTNMA_bAHIss"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["J_F8_Y9v8Jff","Ht19rkhO4AiN","m_IRY1Y24rA3","Vo4AAns75kha","bMu2ACnv6Biu"],"machine_shape":"hm","mount_file_id":"1qVCxYH-oDxEPBTYW31JA_AW2J7tuo_u7","authorship_tag":"ABX9TyNkxfsza9SY8e43MhBqyLLL"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}